{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# acount metadata\nAZURE_SUBSCRIPTION_ID = 'ef3e36f3-4579-469d-b38e-9812ed58ed4f'\nML_WORKSPACE_NAME = 'dairyDemo'\nAZURE_IOT_HUB_NAME = 'dairyFarm'\nRESOURCE_GROUP_NAME = 'IoTEdgeResources'\nLOCATION = 'West US 2'\nSTORAGE_ACCOUNT_NAME = 'dairydatastorage'\nSTORAGE_ACCOUNT_KEY = 'oJ7P/zbnlwzxGHNTVar6eaEU9ZAk+gvM3YrPRKeqZAU5ymrMH4yilNkQP6baAoNi28yi9SwcWCMavRPGIb2phw=='\nSTORAGE_ACCOUNT_CONTAINER = 'dairydata'\nDATASTORE_NAME = 'dairydata'",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os, glob, shutil\nfrom azureml.core import Workspace\n## Configue workspace\n# from azureml.core.workspace import Workspace\n# ws = Workspace.from_config()\nworkspace_name = ML_WORKSPACE_NAME\nsubscription_id = AZURE_SUBSCRIPTION_ID\nresource_group = RESOURCE_GROUP_NAME\nlocation = LOCATION\n\nif not os.path.exists('./aml_config'):\n    os.mkdir('./aml_config')\nws = Workspace.from_config()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## print workspace detail\n\nimport azureml.core\nimport pandas as pd\nfrom azureml.core import Workspace\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\npd.set_option('display.max_colwidth', -1)\npd.DataFrame(data=output, index=['']).T",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.72</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>ef3e36f3-4579-469d-b38e-9812ed58ed4f</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>dairyDemo</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>IoTEdgeResources</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>westus2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                     \nSDK version      1.0.72                              \nSubscription ID  ef3e36f3-4579-469d-b38e-9812ed58ed4f\nWorkspace        dairyDemo                           \nResource Group   IoTEdgeResources                    \nLocation         westus2                             "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## retrieve data from datastore, create TabularDataset \nfrom azureml.core import Datastore, Workspace, Datastore, Dataset\n\ndatastore_name = DATASTORE_NAME\ndatastore = Datastore.get(ws, datastore_name)\nlabel_datastore_path = (datastore,'/label_data_large.csv')\nlabel_dataset = Dataset.Tabular.from_delimited_files(path=label_datastore_path)\n\nrecord_datastore_path_old = (datastore,'/record_data_large.csv')\nrecord_dataset_old = Dataset.Tabular.from_delimited_files(path=record_datastore_path_old)\nrecord_datastore_path = (datastore,'/dairy_milk_daily_data.csv')\nrecord_dataset = Dataset.Tabular.from_delimited_files(path=record_datastore_path)\n\n# preprocessed  \nfull_data_path = record_datastore_path = (datastore,'/preprocessed_data.csv')\nfull_dataset = Dataset.Tabular.from_delimited_files(path=full_data_path)\nfull_data = full_dataset.to_pandas_dataframe()\n\nprint(\"Data retrieved!\")",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Data retrieved!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "full_data.head()",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column1</th>\n      <th>datesql</th>\n      <th>Animal_ID</th>\n      <th>Activity(steps/hr)</th>\n      <th>ActivityDeviation(%)</th>\n      <th>Protein(%)</th>\n      <th>Fat(%)</th>\n      <th>Lactose</th>\n      <th>Conductivity</th>\n      <th>Blood(%)</th>\n      <th>...</th>\n      <th>AnimalStatus</th>\n      <th>Abortion</th>\n      <th>Fresh (Calving)</th>\n      <th>Heat</th>\n      <th>Insemination</th>\n      <th>Not for Insemination</th>\n      <th>Pregnant</th>\n      <th>IsEstrus</th>\n      <th>R</th>\n      <th>Event</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2018-01-03</td>\n      <td>1</td>\n      <td>95.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2018-01-03</td>\n      <td>2</td>\n      <td>166.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2018-01-03</td>\n      <td>3</td>\n      <td>163.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2018-01-03</td>\n      <td>10</td>\n      <td>214.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2018-01-03</td>\n      <td>18</td>\n      <td>154.0</td>\n      <td>45.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.4</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>",
            "text/plain": "   Column1    datesql  Animal_ID  Activity(steps/hr)  ActivityDeviation(%)  \\\n0  0       2018-01-03  1          95.0               -1.0                    \n1  1       2018-01-03  2          166.0               13.0                   \n2  2       2018-01-03  3          163.0               18.0                   \n3  3       2018-01-03  10         214.0               13.0                   \n4  4       2018-01-03  18         154.0               45.0                   \n\n   Protein(%)  Fat(%)  Lactose  Conductivity  Blood(%)  ...    AnimalStatus  \\\n0  0.0         0.0     0.0      0.0           0.0       ...    0              \n1  0.0         0.0     0.0      9.0           0.0       ...    1              \n2  0.0         0.0     0.0      9.1           0.0       ...    1              \n3  0.0         0.0     0.0      9.1           0.0       ...    1              \n4  0.0         0.0     0.0      9.4           0.0       ...    1              \n\n   Abortion  Fresh (Calving)  Heat  Insemination  Not for Insemination  \\\n0  0         0                0     0             0                      \n1  0         0                0     0             0                      \n2  0         0                0     0             0                      \n3  0         0                1     0             0                      \n4  0         0                0     0             0                      \n\n   Pregnant  IsEstrus  R  Event  \n0  1         0                   \n1  1         0                   \n2  1         0                   \n3  0         0                   \n4  1         0                   \n\n[5 rows x 25 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Columns and Explanation \n##### Explaining columns \nFour set of effecting variables:  cows' health, activity, milk composition; \n\nsome of health_cols are formed from categorical data\n1. ['Abortion', 'Fresh (Calving)', 'Heat', 'Insemination', 'Not for Insemination','Pregnant'] : are one-hot encoding from \"Gynecology_Status\" \n2. [\"AnimalStatus\"]  :  {0: \"Dry\", 1: \"Milk\"}\n\n##### training models: \n(it would be great if we could have 2 sets of models with different variables to compare)\n\nonly using [health cols] ( only using [activity cols]), combining [health, activity, milk]       \n(or other combination you think is better)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cow_cols = [\"datesql\",  \"Animal_ID\"]\nhealth_cols = ['Blood(%)','Avg_Milking_Time(seconds)','RestBout(#)','RestRatio(%)','RestTime(min)','Weight(gr)',\"AnimalStatus\",'Abortion', 'Fresh (Calving)', 'Heat', 'Insemination', 'Not for Insemination','Pregnant']\nactivity_cols =['Activity(steps/hr)','ActivityDeviation(%)']\nmilk_cols = ['Protein(%)',\"Fat(%)\",'Lactose','Conductivity']\nlabels = ['R','Event','IsEstrus']",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "###  Upsample and balance minority group\nthese functions could be adjusted based on your training needs"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.utils import resample\n\n# separate minority and majority classes\nX = full_data\nnot_estrus = X[X.IsEstrus==0]\nestrus = X[X.IsEstrus==1]\n\n# upsample minority\nestrus_upsampled = resample(estrus,replace=True, # sample with replacement\n                        n_samples=len(not_estrus), # match number in majority class\n                          random_state=27) # reproducible results\n# combine majority and upsampled minority\nupsampled = pd.concat([not_estrus, estrus_upsampled])\n\n# check new class counts\nupsampled.IsEstrus.value_counts()\ny_train = upsampled.pop('IsEstrus').to_frame()\nX_train = upsampled\n\nX_train.shape;\nsum(y_train.IsEstrus)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "53505"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Training ML models"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create Docker Image\n#### copy from estrus_xh.ipbny"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile estr.py\n# This script generates the  file\n# with the init and run functions needed to \n# operationalize the estrus prediction\n\nimport pickle\nimport json\nimport pandas\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import Ridge\nfrom azureml.core.model import Model\n\n\ndef init():\n    global model\n    # this is a different behavior than before when the code is run locally, even though the code is the same.\n    model_path = Model.get_model_path('model.pkl')\n    # deserialize the model file back into a sklearn model\n    model = joblib.load(model_path)\n    \ninput_sample = pd.DataFrame(data=[{\n    \"Activity(steps/hr)\": 186.0,\n    \"ActivityDeviation(%)\": -11.0,\n    \"Yield(gr)\": 11226.0,\n    \"YieldDeviation(%)\": -15.0,\n    \"Fat(%)\": 4.09,\n    \"FatDeviation(%)\": 7.0,\n    \"Protein(%)\": 2.64,\n    \"ProteinDeviation(%)\": -8.0,\n    \"Lactose(%)\": 4.96,\n    \"LactoseDeviation(%)\": 3.0,\n    \"Conductivity\": 8.3,\n    \"ConductivityDeviation(%)\": -2.0,\n    \"SCC (*1000/ml)\": 26363.0,\n    \"Blood(%)\": 0.03,\n    \"ProductionRate(gr/hr)\": 1528.0\n}])\noutput_sample = np.array([0.9974, 0.0026])\n\n# note you can pass in multiple rows for scoring\ndef run(input_str):\n    try:\n        result = model.predict(data)\n        # You can return any data type, as long as it is JSON serializable.\n        print(\"Prediction is \", result[0])\n        return result.tolist()\n    except Exception as e:\n        result = str(e)\n        \n    if pred[0] == 1:\n        input_json['anomaly']=True\n    else:\n        input_json['anomaly']=False\n        \n    return [json.dumps(input_json)]",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting estr.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This specifies the dependencies to include in the environment\nfrom azureml.core.conda_dependencies import CondaDependencies \n\nmyenv = CondaDependencies.create(conda_packages=['azureml-defaults','azureml-train-automl','inference-schema[numpy-support]','joblib',\n    'numpy',\n    'scikit-learn==0.20.2',\n    'pandas'])\n\nwith open(\"myenv.yml\",\"w\") as f:\n    f.write(myenv.serialize_to_string())",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Add tags to the images\nfrom azureml.core.image import Image, ContainerImage\n\nMODEL_NAME = \"estruspred_new\"\n\nimage_config = ContainerImage.image_configuration(runtime= \"python\",execution_script=\"estr.py\",\n                                 conda_file=\"myenv.yml\",tags = {'area': \"iot\", 'type': \"classification\"},\n                                 description = \"Estrus prediction model\")\n\nimage = Image.create(name = MODEL_NAME,\n                     # this is the model object \n                     models = [model],\n                     image_config = image_config, \n                     workspace = ws)",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "image.wait_for_creation(show_output = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for i in Image.list(workspace = ws,tags = [\"area\"]):\n    print('{}(v.{} [{}]) stored at {} with build log {}'.format(i.name, i.version, i.creation_state, i.image_location, i.image_build_log_uri))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test image"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                               memory_gb = 1, \n                                               tags = {'area': \"iot\", 'type': \"classification\"}, \n                                               description = 'estrus edge prediction')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Test the deployed service\nimport requests\nimport json\nfrom azureml.core.authentication import InteractiveLoginAuthentication\n\n# Get a token to authenticate to the compute instance from remote\ninteractive_auth = InteractiveLoginAuthentication()\nauth_header = interactive_auth.get_authentication_header()\n\n# Create and submit a request using the auth header\nheaders = auth_header\n\n# Add content type header\nheaders.update({'Content-Type':'application/json'})\n\n# Create test sample\ntest_sample = json.dumps({'data': [\n    {\n    \"Activity(steps/hr)\": 186.0,\n    \"ActivityDeviation(%)\": -11.0,\n    \"Yield(gr)\": 11226.0,\n    \"YieldDeviation(%)\": -15.0,\n    \"Fat(%)\": 4.09,\n    \"FatDeviation(%)\": 7.0,\n    \"Protein(%)\": 2.64,\n    \"ProteinDeviation(%)\": -8.0,\n    \"Lactose(%)\": 4.96,\n    \"LactoseDeviation(%)\": 3.0,\n    \"Conductivity\": 8.3,\n    \"ConductivityDeviation(%)\": -2.0,\n    \"SCC (*1000/ml)\": 26363.0,\n    \"Blood(%)\": 0.03,\n    \"ProductionRate(gr/hr)\": 1528.0\n}\n]})\ntest_sample = bytes(test_sample,encoding = 'utf8')\n\n# Send request\n##   URL   ACESSS AND RUN  FOR FRONT END    ------------------*************---------------------\nservice_url = 'http://c7268248-3d6a-409f-87b7-e3b8429325d0.westus2.azurecontainer.io/score'\nresp = requests.post(service_url, test_sample, headers=headers)\nprint(resp.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Deploy container to Azure IoT Edge Device"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Update the workspace object\nws = Workspace.from_config()\n\n# Getting your container details\ncontainer_reg = ws.get_details()[\"containerRegistry\"]\nreg_name=container_reg.split(\"/\")[-1]\ncontainer_url = \"\\\"\" + image.image_location + \"\\\",\"\nsubscription_id = ws.subscription_id\nprint('{}'.format(image.image_location))\nprint('{}'.format(reg_name))\nprint('{}'.format(subscription_id))\nfrom azure.mgmt.containerregistry import ContainerRegistryManagementClient\nfrom azure.mgmt import containerregistry\nclient = ContainerRegistryManagementClient(ws._auth,subscription_id)\nresult= client.registries.list_credentials(RESOURCE_GROUP_NAME, reg_name, custom_headers=None, raw=False)\nusername = result.username\npassword = result.passwords[0].value",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "file = open('estrus-model-deployment-template.json')\ncontents = file.read()\ncontents = contents.replace('__MODULE_NAME', MODEL_NAME)\ncontents = contents.replace('__REGISTRY_NAME', reg_name)\ncontents = contents.replace('__REGISTRY_USER_NAME', username)\ncontents = contents.replace('__REGISTRY_PASSWORD', password)\ncontents = contents.replace('__REGISTRY_IMAGE_LOCATION', image.image_location)\nwith open('./deployment.json', 'wt', encoding='utf-8') as output_file:\n    output_file.write(contents)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}